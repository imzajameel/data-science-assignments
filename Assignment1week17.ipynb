{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b281e6-cdf1-4ca4-97ce-8c24c92359fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week17 \n",
    "#Assignment.1 \n",
    "#Question.1 : What is Bayes' theorem?\n",
    "#Answer.1 : # Bayes' Theorem Explanation :\n",
    "\n",
    "# Bayes' Theorem is a fundamental concept in probability theory that describes the probability of an event\n",
    "#based on prior knowledge of conditions related to the event. It is named after the Reverend Thomas Bayes.\n",
    "\n",
    "# The Formula for Bayes' Theorem:\n",
    "# P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "# Where:\n",
    "# - P(A|B): Probability of event A given that event B has occurred (Posterior Probability).\n",
    "# - P(B|A): Probability of event B given that event A has occurred.\n",
    "# - P(A): Prior probability of event A.\n",
    "# - P(B): Prior probability of event B.\n",
    "\n",
    "# Key Steps in Applying Bayes' Theorem:\n",
    "\n",
    "# 1. **Define Events:**\n",
    "#    - Identify the events A and B that are of interest.\n",
    "\n",
    "# 2. **Assign Prior Probabilities:**\n",
    "#    - Assign prior probabilities (P(A) and P(B)) based on available information or historical data.\n",
    "\n",
    "# 3. **Calculate Likelihood:**\n",
    "#    - Determine the likelihood of event B given that event A has occurred (P(B|A)).\n",
    "\n",
    "# 4. **Calculate Posterior Probability:**\n",
    "#    - Use Bayes' Theorem to calculate the posterior probability P(A|B).\n",
    "\n",
    "# Example Scenario:\n",
    "# - Event A: Having a specific medical condition.\n",
    "# - Event B: Testing positive for a diagnostic test.\n",
    "\n",
    "# Example Code (Bayes' Theorem Calculation):\n",
    "# ```python\n",
    "# # Given probabilities\n",
    "# P_A = prior_probability_of_condition\n",
    "# P_B_given_A = likelihood_of_positive_test_given_condition\n",
    "# P_B = prior_probability_of_positive_test\n",
    "\n",
    "# # Applying Bayes' Theorem\n",
    "# P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "# ```\n",
    "\n",
    "# Applications of Bayes' Theorem:\n",
    "# - Bayesian Statistics: Used in Bayesian inference for updating beliefs based on new evidence.\n",
    "# - Machine Learning: Applied in probabilistic models, such as Naive Bayes classifiers.\n",
    "# - Medical Diagnostics: Used in medical testing and diagnosis.\n",
    "\n",
    "# Bayes' Theorem is a powerful tool for updating probabilities based on new information, making it widely applicable \n",
    "#in various fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfeabfa-2937-4e97-8fcb-ebee3fab8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question.2 : What is the formula for Bayes' theorem?\n",
    "#Answer.2 : # Bayes' Theorem Formula :\n",
    "\n",
    "# Bayes' Theorem is expressed mathematically as follows:\n",
    "\n",
    "# P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "# Where:\n",
    "# - P(A|B): Probability of event A given that event B has occurred (Posterior Probability).\n",
    "# - P(B|A): Probability of event B given that event A has occurred (Likelihood).\n",
    "# - P(A): Prior probability of event A.\n",
    "# - P(B): Prior probability of event B.\n",
    "\n",
    "# This formula provides a way to update our beliefs (the posterior probability) about event A based on new evidence\n",
    "#or information provided by event B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad3ecdf-dd1e-4db0-82d2-418698ced024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question.3 : How is Bayes' theorem used in practice?\n",
    "#Answer.3 : # Practical Application of Bayes' Theorem :\n",
    "\n",
    "# Bayes' Theorem is widely used in practice across various fields. Here's how it can be applied in a practical scenario:\n",
    "\n",
    "# Scenario: Medical Diagnosis\n",
    "\n",
    "# 1. **Define Events:**\n",
    "#    - Event A: Having a specific medical condition.\n",
    "#    - Event B: Testing positive for a diagnostic test.\n",
    "\n",
    "# 2. **Assign Prior Probabilities:**\n",
    "#    - P(A): Prior probability of having the medical condition (based on general prevalence).\n",
    "#    - P(B): Prior probability of testing positive (based on test accuracy and prevalence).\n",
    "\n",
    "# 3. **Calculate Likelihood:**\n",
    "#    - P(B|A): Likelihood of testing positive given the presence of the medical condition (test sensitivity).\n",
    "\n",
    "# 4. **Calculate Posterior Probability:**\n",
    "#    - Use Bayes' Theorem to calculate the probability of having the medical condition given a positive test\n",
    "#result (Posterior Probability).\n",
    "\n",
    "# Example Code (Medical Diagnosis using Bayes' Theorem):\n",
    "# ```python\n",
    "# # Given probabilities\n",
    "# P_A = prior_probability_of_condition\n",
    "# P_B_given_A = likelihood_of_positive_test_given_condition\n",
    "# P_B = prior_probability_of_positive_test\n",
    "\n",
    "# # Applying Bayes' Theorem\n",
    "# P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "# ```\n",
    "\n",
    "# 5. **Decision-Making:**\n",
    "#    - The calculated posterior probability can guide medical professionals in making decisions about further\n",
    "#testing, treatment, or patient counseling.\n",
    "\n",
    "# Applications of Bayes' Theorem in Practice:\n",
    "# - Spam Filtering: Identifying spam emails based on the likelihood of certain words given the email being spam.\n",
    "# - Finance: Assessing the probability of a stock performing well given certain market conditions.\n",
    "# - Machine Learning: Naive Bayes classifiers use Bayes' Theorem for probabilistic classification.\n",
    "\n",
    "# Bayes' Theorem is a powerful tool for updating probabilities based on new evidence, making it applicable in\n",
    "#decision-making, diagnostics, and various real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc1556e-fb80-4add-9db6-287d5ae2b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question.4 : What is the relationship between Bayes' theorem and conditional probability?\n",
    "#Answer.4 : # Relationship between Bayes' Theorem and Conditional Probability :\n",
    "\n",
    "# Bayes' Theorem and conditional probability are closely related concepts in probability theory, and Bayes' \n",
    "#Theorem can be derived from conditional probability.\n",
    "\n",
    "# Conditional Probability Formula:\n",
    "# P(A|B) = P(A and B) / P(B)\n",
    "\n",
    "# Bayes' Theorem Formula:\n",
    "# P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "# Relationship Explanation:\n",
    "\n",
    "# - Conditional Probability (P(A|B)) represents the probability of event A occurring given that event B has occurred.\n",
    "# - Bayes' Theorem provides a way to update this conditional probability by incorporating prior probabilities \n",
    "#(P(A) and P(B)) and the likelihood of event B given event A (P(B|A)).\n",
    "# - The two formulas share the same structure, and Bayes' Theorem can be seen as an extension of conditional\n",
    "#probability that accounts for prior information.\n",
    "\n",
    "# Derivation of Bayes' Theorem from Conditional Probability:\n",
    "# P(A|B) = P(A and B) / P(B)\n",
    "# P(A|B) = P(B|A) * P(A) / P(B)  # Using the definition of conditional probability\n",
    "# Bayes' Theorem obtained by rearranging terms.\n",
    "\n",
    "# Example Code (Conditional Probability and Bayes' Theorem):\n",
    "# ```python\n",
    "# # Given conditional probability\n",
    "# P_A_given_B = P_A_and_B / P_B\n",
    "\n",
    "# # Derivation of Bayes' Theorem\n",
    "# P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "# ```\n",
    "\n",
    "# Applications:\n",
    "# - Both Bayes' Theorem and conditional probability are fundamental in updating beliefs and making predictions\n",
    "#based on new evidence.\n",
    "# - In real-world scenarios, Bayes' Theorem extends the concept of conditional probability by incorporating\n",
    "#additional information.\n",
    "\n",
    "# Understanding the relationship between Bayes' Theorem and conditional probability is crucial for applying \n",
    "#these concepts in probability theory and practical applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca75716-7be9-4ca9-9f89-e3a6227667bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question.5 : How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "#Answer.5 : # Choosing a Naive Bayes Classifier for a Given Problem :\n",
    "\n",
    "# The choice of a Naive Bayes classifier depends on the characteristics of the data and the assumptions that \n",
    "#align with the problem at hand. There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, \n",
    "#Multinomial Naive Bayes, and Bernoulli Naive Bayes.\n",
    "\n",
    "# 1. **Gaussian Naive Bayes:**\n",
    "#    - Assumes that features follow a Gaussian (normal) distribution.\n",
    "#    - Suitable for continuous or real-valued features.\n",
    "#    - Commonly used in problems involving real-valued data, such as sentiment analysis with word embeddings.\n",
    "\n",
    "# 2. **Multinomial Naive Bayes:**\n",
    "#    - Appropriate for problems with discrete features representing counts or frequencies.\n",
    "#    - Often used in text classification where the features are word counts or term frequencies.\n",
    "#    - It works well when the data can be represented as a bag-of-words.\n",
    "\n",
    "# 3. **Bernoulli Naive Bayes:**\n",
    "#    - Suitable for binary feature data (0 or 1).\n",
    "#    - Commonly used in problems like spam classification, where features represent the presence or\n",
    "#absence of specific words.\n",
    "\n",
    "# Steps for Choosing the Right Naive Bayes Classifier:\n",
    "\n",
    "# 1. **Nature of Features:**\n",
    "#    - Assess whether the features are continuous, discrete, or binary.\n",
    "#    - Choose Gaussian, Multinomial, or Bernoulli based on the nature of the features.\n",
    "\n",
    "# 2. **Problem Requirements:**\n",
    "#    - Consider the specific requirements of the problem, such as handling continuous values or binary features.\n",
    "#    - Ensure that the chosen classifier aligns with the problem's characteristics.\n",
    "\n",
    "# 3. **Experimentation and Validation:**\n",
    "#    - Experiment with different Naive Bayes classifiers and validate their performance using cross-validation or \n",
    "#other evaluation metrics.\n",
    "#    - Select the classifier that performs best on the given problem.\n",
    "\n",
    "# Example Code (Choosing Naive Bayes Classifier):\n",
    "# ```python\n",
    "# from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "# # Instantiate different Naive Bayes classifiers\n",
    "# gaussian_nb = GaussianNB()\n",
    "# multinomial_nb = MultinomialNB()\n",
    "# bernoulli_nb = BernoulliNB()\n",
    "# ```\n",
    "\n",
    "# Note: The term \"Naive\" in Naive Bayes implies the assumption of independence between features, and the choice \n",
    "#of the appropriate classifier should align with the underlying assumptions and characteristics of the data.\n",
    "\n",
    "# Choosing the right Naive Bayes classifier involves understanding the nature of the data and selecting a model\n",
    "#that suits the specific requirements of the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7705ab-1665-46de-8c86-7b0ec786367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question.6 : Assignment:\n",
    "#You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "#Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "#each feature value for each class:\n",
    "#Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "#A 3 3 4 4 3 3 3\n",
    "#B 2 2 1 2 2 2 3\n",
    "#Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "#to belong to?\n",
    "#Answer.6 : # Assignment: Naive Bayes Classification with Equal Prior Probabilities :\n",
    "\n",
    "# Given Data:\n",
    "# - Features: X1, X2\n",
    "# - Classes: A, B\n",
    "# - Feature values for each class:\n",
    "\n",
    "#     | Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "#     |-------|------|------|------|------|------|------|------|\n",
    "#     | A     | 3    | 3    | 4    | 4    | 3    | 3    | 3    |\n",
    "#     | B     | 2    | 2    | 1    | 2    | 2    | 2    | 3    |\n",
    "\n",
    "# Features of the new instance: X1 = 3, X2 = 4\n",
    "\n",
    "# Steps for Naive Bayes Classification:\n",
    "\n",
    "# 1. Calculate Prior Probabilities (Equal Priors in this case):\n",
    "#    - P(A) = P(B) = 0.5 (assuming equal priors)\n",
    "\n",
    "# 2. Calculate Likelihoods:\n",
    "#    - P(X1=3|A) = 4/10\n",
    "#    - P(X1=3|B) = 1/7\n",
    "#    - P(X2=4|A) = 3/10\n",
    "#    - P(X2=4|B) = 1/7\n",
    "\n",
    "# 3. Calculate Posterior Probabilities:\n",
    "#    - P(A|X1=3, X2=4) ∝ P(X1=3|A) * P(X2=4|A) * P(A)\n",
    "#    - P(B|X1=3, X2=4) ∝ P(X1=3|B) * P(X2=4|B) * P(B)\n",
    "\n",
    "# 4. Normalize Posterior Probabilities to Obtain Class Probabilities:\n",
    "#    - P(A|X1=3, X2=4) = Normalized P(A|X1=3, X2=4)\n",
    "#    - P(B|X1=3, X2=4) = Normalized P(B|X1=3, X2=4)\n",
    "\n",
    "# 5. Compare Class Probabilities and Choose the Class with the Higher Probability.\n",
    "\n",
    "# Example Code (Naive Bayes Classification):\n",
    "# ```python\n",
    "# # Given data\n",
    "# P_X1_3_given_A = 4/10\n",
    "# P_X1_3_given_B = 1/7\n",
    "# P_X2_4_given_A = 3/10\n",
    "# P_X2_4_given_B = 1/7\n",
    "# P_A = P_B = 0.5\n",
    "\n",
    "# # Calculate Posterior Probabilities\n",
    "# P_A_given_X1_3_X2_4 = P_X1_3_given_A * P_X2_4_given_A * P_A\n",
    "# P_B_given_X1_3_X2_4 = P_X1_3_given_B * P_X2_4_given_B * P_B\n",
    "\n",
    "# # Normalize Posterior Probabilities\n",
    "# Normalized_P_A_given_X1_3_X2_4 = P_A_given_X1_3_X2_4 / (P_A_given_X1_3_X2_4 + P_B_given_X1_3_X2_4)\n",
    "# Normalized_P_B_given_X1_3_X2_4 = P_B_given_X1_3_X2_4 / (P_A_given_X1_3_X2_4 + P_B_given_X1_3_X2_4)\n",
    "\n",
    "# # Compare Class Probabilities\n",
    "# if Normalized_P_A_given_X1_3_X2_4 > Normalized_P_B_given_X1_3_X2_4:\n",
    "#     predicted_class = 'A'\n",
    "# else:\n",
    "#     predicted_class = 'B'\n",
    "# ```\n",
    "\n",
    "# In this example, calculate the posterior probabilities, normalize them, and compare to determine the \n",
    "#predicted class for the new instance (X1=3, X2=4).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
